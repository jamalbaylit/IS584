{"columns": ["id", "conference", "decision", "url", "hasContent", "hasReview", "title", "authors", "abstract"], "data": [["NIPS_2017_570", "NIPS", "Accept", "http://papers.nips.cc/paper/7176-exploring-generalization-in-deep-learning.pdf", "true", "true", "Exploring Generalization in Deep Learning", ["Behnam Neyshabur", "Srinadh Bhojanapalli", "David Mcallester", "Nati Srebro"], "Summary : Paper studies how one can measure how well a network will generalize . ( This is linked to implicit regularization present in our current optimization methods . ) In particular , the paper links the capacity of neural networks to four different path-norm measures of the weights of the network . They revisit/define margins , lipschitz continuity and ( expected ) sharpness as measures of network capacity/generalization . An interesting experiment is done where the ability of these measures to predict how well a network can generalize is carried out : a network is trained on a subset of a training set , along with different fractions of corrupted labels for other datapoints ( different fractions for different networks ) . The measures are then used to predict how well a network might generalize . An interesting paper . ( Some of the text has minor typos though . ) But it seems that the conclusion from the middle pane of Figures 3 , 4 that spectral norm and path l2 norm are the best measures for generalization , as they seem to correlate with test error in both cases , whereas the others do n't . ( The path l1 norm also does badly ) . For better comparison , it would have been good to see Figure 4 for CIFAR10 also . Minor comments : I assume the epsilon is added after the softmax ( in ( 2 ) ) ? Is there some rescaling then ? Why does the left of Figure 2 show that sharpness is unstable ? This seems to be more of a feature of Figures 3 , 4 ?"], ["NIPS_2018_1005", "NIPS", "Accept", "http://papers.nips.cc/paper/8291-sparse-pca-from-sparse-linear-regression.pdf", "true", "true", "Sparse PCA from Sparse Linear Regression", ["Guy Bresler", "Sung Min Park", "Madalina Persu"], "The paper proposes an approach to reduce solving a special sparse PCA to a sparse linear regression ( SLR ) problem ( treated as a black-box solution ) . It uses the spiked covariance model [ 17 ] and assumes that the number of nonzero components of the direction ( u ) is known , plus some technical conditions such as a restricted eigenvalue property . The authors propose algorithms for both hypothesis testing and support recovery , as well as provide theoretical performance guarantees for them . Finally , the paper argues that the approach is robust to rescaling and presents some numerical experiments comparing two variants of the method ( based on SLR methods FoBa and LASSO ) with two alternatives ( diagonal thresholding and covariance thresholding ) . Strengths : - The addressed problem ( sparse PCA ) is interesting and important . - The paper is well-written , the general idea is relatively simple and easy to understand ( the implementation of Algorithms 1 and 2 also looks straightforward ) . - As the underlying sparse linear regression ( SLR ) approach is treated as a black-box ( as long as it satisfies Condition 2.4 ) , the approach has several variants depending on the SLR used . - Both hypothesis testing and support recovery are addressed and the paper provides theoretical performance guarantees for them . - The authors also present experimental comparisons to demonstrate the advantages of the method over some previous solutions . Weaknesses : - It is obvious that there is a strong connection between PCA and linear regression ( see for example [ 41 ] ) , thus the originality of the general idea is limited . - The spiked covariance model for PCA is quite restrictive ( for example , Gaussian white noise ) and unlikely to be met in practical applications . In fact Gaussianity is crucial for this approach , which makes the results less significant . - The assumption that the number of nonzero components of u are known is strong ( though the authors argue that there are adaptive methods to adjust this ) . - It is not clear how easy it is to check / verify for a particular problem and SLR method that Condition 2.4 holds . It looks like a strong assumptions which is hard to verify . Ideally , the authors should have demonstrated verifying this condition on an example . - The fact that the underlying SLR method is treated as a black-box might hide the problem of selecting the appropriate SLR method . Which one should be used for various problems ? Minor comments : - The authors argue that though random design matrices for linear regression can arise , it makes no difference to assume that it is deterministic ( by conditioning ) . This argument is a bit misleading , as it is only true if the design matrix ( \\mathbb { X } ) and the noise vector ( w ) affecting the observations are independent . This is not the case , for example , if the linear regression problem arises from a time-series problem , such as estimating the parameters of an autoregressive model ( in which case the design matrix can not be assumed to be deterministic ) . - It is not a good practice to cite works that are only available on arXiv ( as they did not go through any review process , they could contain unsupported claims , etc . ) .Post-rebuttal comments : Thank you for your replies . It is a nice feature that the presented approach can turn a black-box SLR to a SPCA solver . Nevertheless , it requires strong assumptions , for example , the spiked covariance model , knowledge of sparsity , and RE , which limit its theoretical and practical relevance . I understand that these assumptions could be relaxed a bit , for example , the method could be extended to sub-Gaussian variables and unknown sparsity could be handled by binary search ( for hypothesis testing ) . It would be good to discuss these issues in more detail in the revised paper ."], ["ICLR_2020_222", "ICLR", "Accept (Poster)", "http://openreview.net/pdf/1c76c8b597ee076527d77a8b9befd563bdeb5733.pdf", "true", "true", "Intrinsic Motivation for Encouraging Synergistic Behavior", ["Rohan Chitnis", "Shubham Tulsiani", "Saurabh Gupta", "Abhinav Gupta"], "The paper focuses on using intrinsic motivation to improve the exploration process of reinforcement learning agents in tasks with sparse-reward and that require multi-agent to achieve . The authors proposed to encourage the agents toward the actions which changed the world in the ways that `` would not be achieved if the agents were acting alone `` . The experiments are done with dual-arm manipulation . The idea of guiding the agents toward the actions that they can not do without concurrent cooperation is interesting . In this paper , it is presented by two types of intrinsic rewards : compositional prediction error and prediction disparity . The core component is the composition of these single-agent prediction model ( f^ { composed } ) . Although the formulation proposed is only based on intuition , the authors did enough ablation study to highlight the advantage of this loss function . Areas to improve : + The objects used in the experiment are symmetric , it is good to open your study to the task in which the objects are asymmetric or even deformable . + It is good to extend to the problem of multiple-agents ( > 2 ) , while the order of agents who acts is important to compute `` the expected outcome with individual agents acting sequentially `` ( for now , you only assume that the A will act first then the B acts later ) ."], ["NIPS_2017_519", "NIPS", "Accept", "http://papers.nips.cc/paper/7125-maximizing-subset-accuracy-with-recurrent-neural-networks-in-multi-label-classification.pdf", "true", "true", "Maximizing Subset Accuracy with Recurrent Neural Networks in Multi-label Classification", ["Jinseok Nam", "Eneldo Loza Menc\u00eda", "Hyunwoo J. Kim", "Johannes F\u00fcrnkranz"], "This paper presents a novel approach to learning the joint probability of labels in multi-label classification problems . The authors introduce a formulation where the joint probability is computed over a sequence of positive labels . The novel approach is analyzed empirically on three benchmark datasets . As claimed by the authors , the novel approach has a number of advantages compared to existing methods such as PCCs . One important advantage is that the length of the chain decreases by considering positive labels only , resulting in a more compact model that suffers less from error propagation . In addition , the use of seq-to-seq neural nets instead of more traditional base learners in PCC can also result in performance gains in areas where deep learning is typically successful ( images , text , speech , etc . ) .In general I find the method proposed in this paper interesting . However , I do see a few possibilities for further improving the paper : - In the beginning of the paper the authors indicate that they are interested in minimizing the subset zero-one loss . This might be a natural choice , given that a joint probability distribution over labels is constructed . However , in the experiments , the authors start to focus on other loss functions for which the proposed framework is not suited . It is clear that a BR-style method should be preferred for Hamming loss , whereas more complicated approaches are needed to optimize the different variants of the F-measure . The analyzed methods , neither the PCC baseline , nor the method of the authors , optimize the F-measure . More complicated algorithms are needed for that , see e.g .Waegeman et al .On the Bayes optimality of F-measure maximizers , JMLR 2014 . - In light of this discussion , it is also a bit strange to optimize subset zero-one loss in MLC applications with hundreds of labels . Subset zero-one loss is for sure not the measure of interest in extreme MLC applications ."], ["ICLR_2018_861", "ICLR", "Reject", "http://openreview.net/pdf/fc0d41d3e64c58ed947de9a5b43e2ec219a857a9.pdf", "true", "true", "A dynamic game approach to training robust deep policies", ["Olalekan Ogunmolu"], "The authors propose to incorporate elements of robust control into guided policy search , in order to devise a method that is resilient to perturbations and ( presumably ) model mismatch . The idea behind the method and the discussion in the introduction and related work is interesting and worthwhile , and I think that combining elements from robust control and reinforcement learning is a very promising direction to explore . However , in its present state , the paper is very hard to evaluate , perhaps because the submission was a bit rushed . It may be that the authors can clarify some of these issues in the response period . First , the authors repeatedly state that perturbations are applied to the policy parameters . This seems very strange to me , as typically robust control considers perturbations to the state or control . And reading the actual method , I ca n't actually figure out how perturbations are applied to the parameters -- as near as I can tell , the perturbations are indeed applied to the controls . So which is it ? There is quite a lot of math in the derivation , and it 's unclear which parts relate to the standard guided policy search algorithm , and which parts are new . After reading the technical sections several times , my best guess is that the method corresponds to using an adversarial trajectory optimization setup to generate supervision for training a policy . So only the trajectory optimization phase is actually different . Is that true ? Or are there other modifications ? Some sort of summary of the overall method would have been appreciated , or else a clearer separation of new and old components . The evaluation also leaves a lot to be desired . What kind of perturbations are actually being considered ? Are they all adversarial perturbations ? Do the authors actually test model mismatch or other more natural conditions where robustness would be beneficial ? In the end , I was unable to really interpret what the experiments are trying to get across , which makes it hard for me to tell if the method actually works or improves on anything . In its present state , the paper is very hard to parse , and the evaluation appears too rushed for me to be able to deduce how well the method works . Hopefully the authors can clarify some of these issues in the response period ."], ["ICLR_2020_993", "ICLR", "Reject", "http://openreview.net/pdf/ec84da186c47d5983042e4bfe010bdb6baeeba64.pdf", "true", "true", "Generative Adversarial Networks For Data Scarcity Industrial Positron Images With Attention", ["Mingwei Zhu", "Min Zhao", "Min Yao", "Ruipeng Guo"], "This work proposes a method to transfer information from PET imaging data from the medical domain , where data is highly available , to the industrial one , where data is scarce , in the context of non-destructive material quality evaluation . The basic idea seems interesting , but unfortunately in the present form he paper is very difficult to appreciate , as it lacks of important details concerning methodology , experimental results , and comparison with respect to the state-of-the-art . Moreover , the manuscript still appears in a draft form . Sentences are often broken , the text presents many typos and grammar mistakes , and the citations are not understandable . Missing methodological details are grouped in the following parts of this review . Section 3.2 Encoder Paragraph 2 : The authors claim that they introduce the knowledge of migration learning without explaining it . Where does this concept come from ? Is there a literature about it or is this a new concept ? Medical images are fitted though a variational auto encoder ( VAE ) ( citation missing ) . The encoder description is minimal and lacks of implementation details ( see Eq .3 ) , while the decoder description is missing throughout the paper . Eq . ( 2 ) : the authors write that they obtain a distribution p ( x ) according to Eq . ( 2 ) , but this equation is just the formula for the sample mean , where p ( x ) is sampled and not computed . Eq . ( 3 ) : f1 and f2 are never made explicit in the paper so we do not know if they are linear or non-linear functions . The prior p ( Z ) is decomposed as a summation of posteriors p ( Z|X ) and the choice to have these posteriors equal to N ( 0,1 ) ( 1-dimensional , which is unusual ) regardless of the data point X is not explained . Section 3.3 Feature extraction memory module Feature extraction from industrial images is done through principal component analysis ( PCA ) . In the same paragraph is written that features are extracted through convolution neural networks ( CNN ) . So it is not clear if there is an arbitrary choice to use PCA or CNN , and what are the conditions when this happens . Eq . ( 6 ) : the score between z_t ( medical image distribution ) and y_s ( industrial image feature vector ) is computed as scalar product dot ( z_t , W_a * y_s ) . The key link is the linear mapping W_a , which is never made explicit in the paper . How do the authors compute W_a ? Section 4.1 Implementation details the networks called \u201c identification network \u201d and \u201c front-end network \u201d are not well defined . They may refer to the VAE , the CNN , the Adversarial Nets . There is too much ambiguity . A captioned figure can help in resolving the ambiguities . Section 4.2 Dataset In the first paragraph the authors cite a dataset of CT images , while the main focus of the paper is on PET images . How the CT images comes into play ? Section 4.3 Evaluation The authors compare their method with respect to other three methods , namely VAE , DCGAN , and WGAN . The implementation details of the competing methods are not described so we can not be sure about the fairness of the comparison . Other considerations Introduction , 4th paragraph : \u201c imaging quality is higher \u201d With respect to what ? Usually PET images have the worst quality in the medical domain . Introduction , 3rd-to-last paragraph : \u201c We use the medical CT image ... \u201d . Should be PET images Related work : This section is a list of works and the relation with the current paper is not highlighted . \u201c lung cancer cakes \u201d what are they ? Paragraph 3.2 : \u201c excessive pursuit of quality \u201d why is it bad ? \u201c migration learning \u201d do they mean transfer learning ? Equation 2 and 3 in relation to a clustering problem never pointed out before in the paper . Paragraph 4.1 . What is the meaning of \u201c Adam algorithm ( =0.5 ) \u201d ? Figures 1 and 2 have very minimal captions . What do they represent ? Citation formatting problem : name and surname are switched . Journal/conferences often omitted ."], ["NIPS_2019_998", "NIPS", "Accept", "http://papers.nips.cc/paper/9292-learning-stable-deep-dynamics-models.pdf", "true", "true", "Learning Stable Deep Dynamics Models", ["J. Zico Kolter", "Gaurav Manek"], "The paper presents a method for constructing neural network architectures that have build-in theoretical guarantees of Lyapunov stability - meaning that the equilibrium will be in the origin and for any initial condition , the network will produce trajectories that converge to the equilibrium . The method is evaluated on the N-link pendulum and video generation problems . The method\u00e2\u0080\u0099s significance comes from two different reasons . First , Lyapunov stability for the system is very difficult to prove with classical methods . Second , deep learning methods are largely empirical , without theoretical guarantees , limiting their applicability for life-critical system . This paper presents a method for learning autonomous dynamics that is guaranteed to be Lyapunov stable , without having the classical toolset . This methodology is original and potentially very useful for many applications , beyond classic controls and videos . For example , protein folding , robotics , weather predictions , material design , etc . The quality of the paper overall is good , although it varies . The theoretical potion is solid . The contribution is clear , well-motivated , and structured well . The empirical validation is somewhat lacking in quality . While the authors are commended for exploring two very different domains ( classic controls and video generation ) , the empirical validation is missing some key elements . For example : - It is not clear how the method would perform on a system without equilibrium , or for that matter the link in the upright initial position . - How do the learned and ground truth models perform in the presence of noise ? - Details about the training are missing : 1 . methodology for gathering the training set ; 2 . why the convex network has 60 layers ( and in the previous example , it contranied 100 neurons per layer ) ; 3 . system info is missing in both examples ( equations for the pendulum with the damping factor and reference to the video dataset for the video prediction dataset ) . 4 .Figure 5 : Over how many initial conditions was the Figure compiled ? Please show error bars . In addition , that authors should include and discuss the following related work : Learning Stabilizable Dynamical Systems via Control Contraction Metrics , Singh et al .WAFR 2018 Continuous Action Reinforcement Learning for Control-Affine Systems with Unknown Dynamics , Faust et al , Acta Automatica Sinica , 2014 The presentation of the paper is excellent . The authors make a theoretical paper very easy to read , and logically introduce one step at the time new notation and the elements of the method . Some minor comments : - Lines 59-60 : stating that those conditions are sufficient but not necessary is more clear . - Line 113 : What differentiable tools . Please cite ? - Line 132-133 - Please , either prove or remove the claims . - Line 145 : is V is - > if V is - Line 167 : The fact the V - > The fact that V - Line 192 : angular velocity \\theta - > angular velocity \\dot \\theta - Please go through the math and use standard notations for vectors ( vs scalars ) . Overall , strong potential theoretical result , with lacking supporting evidence as how well it really works in practice . -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Update after author response : Thank you for the response and clarifying the points . The paper presents a strong theoretical contribution , and I leave the score unchanged ."], ["ICLR_2019_981", "ICLR", "Reject", "http://openreview.net/pdf/9d214dc113ef31d4b8071ed6b3ace7e96f05d757.pdf", "true", "true", "Shaping representations through communication", ["Olivier Tieleman", "Angeliki Lazaridou", "Shibl Mourad", "Charles Blundell", "Doina Precup"], "1 ) Can we think of this setup as sparse + desoising AE ? As opposed to being similar to dropout ? For better clarity , describe what the setup reduces to for length 1 AE setting in the CbAE ? 2 ) What is the influence of regularization in AEs , including denoising or contractive criteria ? And jumping to experiments , these varieties of AEs are not evaluated ? Since the criterion of encoder-decoder selection corresponds to noising , this evaluation is critical . 3 ) The natural baseline here is an ensemble of AEs . Should be compared . 4 ) How similar are the representations across the decodes in the community ( not the RSA setup used in page 8 ) ? This gives clear info on how big the community should be ? And more critically , whether the cross-decoder representations are repetitive/redundant ( i.e. , an intrinsic fitting issue for CbAE ) ? 5 ) Is the statement following eq 3 the other way around ? Positive SCG is good or bad ? Confusing , explain ? 6 ) What about non-monotonic learning curves ? How is SCG formulated for such a setting ? A windowed average of learning curve thresholds is a better criterion . A more broader question is why using this criterion makes sense for the goal of better representation building ? 7 ) Why is iteration 64 , community size 16 consistently -ve SCG in CIFAR ? And for the same community size the RSA is going down after increasing initially in Table 3 ? Something going on here . Intuitively , this implies bounds on the community size ( like with random forests ensemble setting -- a tradeoff of number of trees vs. depth ) ."], ["NIPS_2019_535", "NIPS", "Accept", "http://papers.nips.cc/paper/8829-scalable-inference-of-topic-evolution-via-models-for-latent-geometric-structures.pdf", "true", "true", "Scalable inference of topic evolution via models for latent geometric structures", ["Mikhail Yurochkin", "Zhiwei Fan", "Aritra Guha", "Paraschos Koutris", "XuanLong Nguyen"], "The authors propose a set of models and inference algorithms to model the evolution of topics over time . The proposed set of models are novel in terms of both the generative models and inference techniques . The novelty in generative models is achieved by representing a set of topics at a given time as a topic polytope and modeling evolution of topics as trajectories in the geometric space of the polytopes . The proposed inference approach is fast and scalable , and lends itself well to online learning and distributed computing . The authors describe the motivation for the generative process and the algorithms in sufficient detail . The supplement further elaborates on inference details and sensitivity to priors . Experimental results demonstrate improvements in perplexity and significant speed ups in run time . The major contributions are clear and significantly advance the state of research ."], ["ICLR_2018_666", "ICLR", "Reject", "http://openreview.net/pdf/32cfc1b0b53e5054c9e6c8393afa84289ab1d923.pdf", "true", "true", "Learning Generative Models with Locally Disentangled Latent Factors", ["Brady Neal", "Alex Lamb", "Sherjil Ozair", "Devon Hjelm", "Aaron Courville", "Yoshua Bengio", "Ioannis Mitliagkas"], "The paper investigates the potential of hierarchical latent variable models for generating images and image sequences . The paper relies on the ALI model from [ Dumoulin et al , ICLR'16 ] as the main building block . The main innovation in the paper is to propose to train several ALI models stacked on top of each other to create a hierarchical representation of the data . The proposed hierarchical model is trained in stages . First stage is an original ALI model as in [ Dumoulin et al ] . Each subsequent stage is constructed by using the Z variables from the previous stage as the target data to be generated . The paper constructs models for generatation of images and image sequences . The model for images is a 2-level ALI . The first level is similar to PatchGAN from [ 1 ] but is trained as an ALI model . The second layer is another ALI that is trained to generate latent variables from the first layer . [ 1 ] Isola et al .Image-to-Image Translation with Conditional Adversarial Networks , CVPR'17 In the the model for image sequences the hierarchy is somewhat different . The top layer is directly generating images and not patches as in the image-generating model . Summary : I think this paper presents a direct and somewhat straightforward extension of ALI . Therefore the novelty is limited . I think the paper would be stronger if it ( 1 ) demonstrated improvements when compared to ALI and ( 2 ) showed advantages of hierarchical training on other datasets , not just the somewhat simple datasets like CIFAR and Pacman . Other comments / questions : - baseline should probably be 1-level ALI from [ Dumoulin et al . ] .I believe in the moment the baseline is a standard GAN . - I think the paper would be stronger if it directly reproduced the experiments from [ Dumoulin et al . ] and showed how hierarchy compares to standard ALI without hierarchy . - the reference Isola et al . [ 1 ] should ideally be cited since the model for image genration is similar to PatchGAN in [ 1 ] - Why is the video model in this paper not directly extending the image model ? Is it due to limitation of the implementation or direclty extending the iamge model did n't work ?"]]}